{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllLife Bank Personal Loan Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "AllLife Bank has a growing customer base. Majority of these customers are liability customers (depositors) with varying size of deposits. The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business and in the process, earn more through the interest on loans. In particular, the management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). \n",
    "\n",
    "A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio with a minimal budget.\n",
    "\n",
    "You as a Data scientist at AllLife bank has to build a model that will help marketing department to identify the potential customers who have higher probability of purchasing the loan. This will increase the success ratio while at the same time reduce the cost of the campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* To predict weather a liability customer will buy personal loans.\n",
    "* Which variables are most significant.\n",
    "* Which segment of customers should be targeted more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "* ID: Customer ID\n",
    "* Age: Customer’s age in completed years\n",
    "* Experience: #years of professional experience\n",
    "* Income: Annual income of the customer (in thousand dollars)\n",
    "* ZIP Code: Home Address ZIP code.\n",
    "* Family: the Family size of the customer\n",
    "* CCAvg: Avg. spending on credit cards per month (in thousand dollars)\n",
    "* Education: Education Level. 1: Undergrad; 2: Graduate;3: Advanced/Professional\n",
    "* Mortgage: Value of house mortgage if any. (in thousand dollars)\n",
    "* Personal_Loan: Did this customer accept the personal loan offered in the last campaign?\n",
    "* Securities_Account: Does the customer have securities account with the bank?\n",
    "* CD_Account: Does the customer have a certificate of deposit (CD) account with the bank?\n",
    "* Online: Do customers use internet banking facilities?\n",
    "* CreditCard: Does the customer use a credit card issued by Bank?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To build linear model for statistical analysis and prediction\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Loan_Modelling.csv\")\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")  # f-string\n",
    "\n",
    "np.random.seed(1)  # To get the same random results every time\n",
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore data to get more insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The variable ID does not add any interesting information. There is no association between a person's customer ID and loan, also it does not provide any general conclusion for future potential loan customers. We can neglect this information for our model prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No columns have null data in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The mean age of the customers is 45 with standard deviation of 11.5. \n",
    "* The mean of Avg. spending on credit cards per month is 1.93 with standard deviation of 1.75. \n",
    "* The mean annual income of the customer is 73.77 with standard deviation of 46. \n",
    "* The mean value of house mortgage is 56.5 with standard deviation of 101.71. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Income.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Experience.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see there are few negative values in experience which is practically not possible\n",
    "# We assume that these negative signs here are by mistake, so we will replace them with positive signs\n",
    "df.Experience.replace(-1,1,inplace=True)\n",
    "df.Experience.replace(-2,2,inplace=True)\n",
    "df.Experience.replace(-3,3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Family.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Securities_Account.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CCAvg.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Education.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Mortgage.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CD_Account.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Online.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CreditCard.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ZIPCode.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to group them on the basis of first 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first digit indicates one of the regions and second digit indicates the sub region or one of the postal circles (States),\n",
    "# So using first 2 digits will do work for our model\n",
    "df['ZIPCode'] = df['ZIPCode'].astype(str)\n",
    "print(df['ZIPCode'].str[0:2].nunique())\n",
    "df['ZIPCode'] = df['ZIPCode'].str[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing unusual seen in the values of any of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Look at correlation values\n",
    "corr=df.corr()\n",
    "fig,ax=plt.subplots(figsize=(12,12))\n",
    "ax=sns.heatmap(corr,annot=True,square=True,fmt=\".2f\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age and Experience seems to highly correlated and that is very obvious too, as age increases, experience also increases\n",
    "* Age, Experience, Online and credit card seems to be very less correlated with Personal loan\n",
    "* Income and CCAvg seems to be correlated and that's obvious too, a person with higher salary will spend more on an average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Look at outliers in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection using boxplot\n",
    "numerical_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "for i, variable in enumerate(numerical_col):\n",
    "                     plt.subplot(5,4,i+1)\n",
    "                     plt.boxplot(df[variable],whis=1.5)\n",
    "                     plt.tight_layout()\n",
    "                     plt.title(variable)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Income, CCavg, Mortgage, Personal_loan, Securities_Account, CD_Account shows outliers, but they actually are not outliers - these are the variables that not every person has some value in. so there is nothing wrong in having such values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at details of dataset using pandas_profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
    "import pandas_profiling\n",
    "df.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "* The data set got 0 missing cells.\n",
    "* It got 7 numeric variables: ‘Age’, ‘CC_Avg’, ‘ID’, ‘Income’, ‘Mortgage’, ‘Zip_Code’, ‘Experience’\n",
    "* It got 2 categorical variables: ‘Education’, ‘Family’\n",
    "* It got 5 Boolean variables: ‘CD_Account’, ‘Credit_Card’, ‘Online’, ‘Personal_Loan’, ‘Securities Account’\n",
    "* Personal Loan is highly correlated with Income, average spending on Credit cards, mortgage & if the customer has a certificate of deposit (CD) account with the bank.\n",
    "* Also, Experience is highly correlated with Age (ρ = 0.994214857)\n",
    "\n",
    "### Categorical\n",
    "* 42% of the candidates are graduated, while 30% are professional and 28% are Undergraduate.\n",
    "* Around 29% of the customer’s family size is 1.\n",
    "\n",
    "### Boolean\n",
    "* 94% of the customer doesn’t have a certificate of deposit (CD) account with the bank.\n",
    "* Around 71% of the customer doesn’t use a credit card issued by UniversalBank.\n",
    "* Around 60% of customers use internet banking facilities.\n",
    "* Around 90% of the customer doesn’t accept the personal loan offered in the last campaign.\n",
    "* Around 90% of the customer doesn’t have a securities account with the bank.\n",
    "\n",
    "### Numeric\n",
    "* The mean age of the customers is 45 with standard deviation of 11.5. Also, we had estimated the average age in hypothesis testing between 30–50. The curve is slightly negatively skewed (Skewness = -0.02934068151) hence the curve is fairly symmetrical\n",
    "* The mean of Avg. spending on credit cards per month is 1.93 with standard deviation of 1.75. The curve is highly positive skewed (Skewness = 1.598443337)\n",
    "* The mean annual income of the customer is 73.77 with standard deviation of 46. The curve is moderately positive skewed (Skewness = 0.8413386073)\n",
    "* The mean value of house mortgage is 56.5 with standard deviation of 101.71. The curve is highly positive skewed (Skewness = 2.104002319) and there are a lot of outlier’s present (Kurtosis = 4.756796669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Income is positively skewed. Majority of the customers have income between 45K and 55K. We can confirm this by saying the mean is greater than the median.\n",
    "* CCAvg is also a positively skewed variable and average spending is between 0K to 10K and majority spends less than 2.5K\n",
    "* Experience is normally distributed with more customer having experience starting from 8 years. Here the mean is equal to median. \n",
    "* The variables family and education are ordinal variables. The distribution of families is evenly distributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_plot(x):\n",
    "    sns.set(palette='nipy_spectral')\n",
    "    tab1 = pd.crosstab(x,df['Personal_Loan'],margins=True)\n",
    "    print(tab1)\n",
    "    print('-'*120)\n",
    "    tab = pd.crosstab(x,df['Personal_Loan'],normalize='index')\n",
    "    tab.plot(kind='bar',stacked=True,figsize=(10,5))\n",
    "    plt.legend(loc='lower left', frameon=False)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_val = ['Family','Education','Personal_Loan','Securities_Account','CD_Account','Online','CreditCard']\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "for i , column in enumerate(categorical_val,1):\n",
    "    stacked_plot(df[column])\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of income and education on personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Education',y='Income',hue='Personal_Loan',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  It seems the customers whose education level is 1 is having more income. However customers who has taken the personal loan have the same income levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of Securities_account on Personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Securities_Account\", data=df,hue=\"Personal_Loan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Majority of customers who does not have loan have securities account, this might be happening because majority of people don't have loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of Family size on Personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Family',data=df,hue='Personal_Loan',palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Family size does not have any impact in personal loan. But it seems families with size of 3 and 4 are more likely to take loan. When considering future campaign this might be good association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of CDAccount on Personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='CD_Account',data=df,hue='Personal_Loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Customers who does not have CD account , does not have loan as well. This seems to be majority. But almost all customers who has CD account has loan as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of Age on Personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Age',data=df,hue='Personal_Loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age doesn't have impact on Personal Loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of 0s' , (df.Personal_Loan == 0).sum(axis=0))\n",
    "print('No. of 1s' , (df.Personal_Loan == 1).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here bank can face 2 types of losses\n",
    " 1. False negative - Person would take a loan but model says - he won't - Loss of opportunity\n",
    " 2. False positive - Model says person will take a loan, but in actual person won't - Increased Marketing cost\n",
    "\n",
    "### Which loss is bigger?\n",
    " - False negatives i.e. Loss of Oppurtunity (Typically marketing cost is small)\n",
    " - So we want to reduce False negatives and for that we have to maximize the Recall while keeping Accuracy in balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining X and Y variables\n",
    "# Here we had 6 categorical variables but 4 of them are binary, so we'll have same results with them even after creating dummies\n",
    "# education and family have order within them, so we won't convert them to dummies\n",
    "# so let's not change them and make dummies only for Zipcode\n",
    "\n",
    "df[\"ZIPCode\"] = df[\"ZIPCode\"].astype('category')\n",
    "\n",
    "X = df.drop(['Personal_Loan'], axis=1)\n",
    "Y = df[['Personal_Loan']] \n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "#Splitting data in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original dataset', Y.Personal_Loan.value_counts(normalize=True))\n",
    "print('Train dataset', y_train.Personal_Loan.value_counts(normalize=True))\n",
    "print('Test dataset', y_test.Personal_Loan.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data split looks uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a function for better visualization of confusion matrix\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#mat_train = confusion_matrix(y_train,pred_train)\n",
    "\n",
    "\n",
    "def make_confusion_matrix(y_actual,y_predict,labels=[1, 0]):\n",
    "    '''\n",
    "    y_predict: prediction of class\n",
    "    y_actual : ground truth  \n",
    "    '''\n",
    "    cm=confusion_matrix( y_predict,y_actual, labels=[1, 0])\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n",
    "                  columns = [i for i in ['1','0']])\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "              zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure(figsize = (7,5))\n",
    "    sns.heatmap(df_cm, annot=labels,fmt='')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build model using Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before making the model, first let's check if our variables has multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are different ways of detecting(or  testing) multi-collinearity, one such way is Variation Inflation Factor.\n",
    "\n",
    "* **Variance  Inflation  factor**:  Variance  inflation  factors  measure  the  inflation  in  the variances of the regression coefficients estimates due to collinearities that exist among the  predictors.  It  is  a  measure  of  how  much  the  variance  of  the  estimated  regression coefficient βk is “inflated”by  the  existence  of  correlation  among  the  predictor variables in the model. \n",
    "\n",
    "* General Rule of thumb: If VIF is 1 then there is no correlation among the kth predictor and the remaining predictor variables, and  hence  the variance of β̂k is not inflated at all. Whereas if VIF exceeds 5, we say there is moderate VIF and if it is 10 or exceeding 10, it shows signs of high multi-collinearity. But the purpose of the analysis should dictate which threshold to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with numerical column only\n",
    "num_feature_set = X.copy()\n",
    "from statsmodels.tools.tools import add_constant\n",
    "num_feature_set = add_constant(num_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif_series1 = pd.Series([variance_inflation_factor(num_feature_set.values,i) for i in range(num_feature_set.shape[1])],index=num_feature_set.columns)\n",
    "print('Series before feature selection: \\n\\n{}\\n'.format(vif_series1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age and Experience seems to be highly correlated, so we will drop one of them depending on which has less effect on making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(num_feature_set, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "lg = logit.fit()\n",
    "\n",
    "print(lg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop('Age', axis = 1)\n",
    "X_test1 = X_test.drop('Age', axis = 1)\n",
    "\n",
    "logit1 = sm.Logit(y_train, X_train1)\n",
    "lg1 = logit1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check accuracy and recall for this model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "pred_train1 = lg1.predict(X_train1)\n",
    "pred_test1 = lg1.predict(X_test1)\n",
    "\n",
    "pred_train1 = np.round(pred_train1)\n",
    "pred_test1 = np.round(pred_test1)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train1) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test1))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train1) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test1))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train1) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test1))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train1) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.drop('Experience', axis = 1)\n",
    "X_test2 = X_test.drop('Experience', axis = 1)\n",
    "\n",
    "logit2 = sm.Logit(y_train, X_train2)\n",
    "lg2 = logit2.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check accuracy and recall for this model\n",
    "\n",
    "pred_train2 = lg2.predict(X_train2)\n",
    "pred_test2 = lg2.predict(X_test2)\n",
    "\n",
    "pred_train2 = np.round(pred_train2)\n",
    "pred_test2 = np.round(pred_test2)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train2) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test2))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train2) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test2))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train2) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test2))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train2) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The accuracy on lg1 and lg2 is same\n",
    "* But let's proceed with lg1 i.e. we should drop age variable and keep Experience variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check VIF score again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "num_feature_set = num_feature_set.drop(['Age'], axis = 1)\n",
    "vif_series1 = pd.Series([variance_inflation_factor(num_feature_set.values,i) for i in range(num_feature_set.shape[1])],index=num_feature_set.columns)\n",
    "print('Series before feature selection: \\n\\n{}\\n'.format(vif_series1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now none of the variables have high VIF score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Look at summary of lg1 and make interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lg1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observe that p value of Experience, Securities_Account and all 6 classes of ZIP code is greater than 0.05, they seem to be insignificant\n",
    "* Let's Drop them one by one and observe how our model changes\n",
    "* This is something we observed during EDA also, Experience and Securities_Account didn't showed any specific pattern with personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train1.drop(['ZIPCode_91', 'ZIPCode_92', 'ZIPCode_93', 'ZIPCode_94', 'ZIPCode_95', 'ZIPCode_96'], axis = 1)\n",
    "X_test3 = X_test1.drop(['ZIPCode_91', 'ZIPCode_92', 'ZIPCode_93', 'ZIPCode_94', 'ZIPCode_95', 'ZIPCode_96'], axis = 1)\n",
    "\n",
    "\n",
    "logit3 = sm.Logit(y_train, X_train3)\n",
    "lg3 = logit3.fit()\n",
    "\n",
    "# Let's check accuracy and recall for this model\n",
    "pred_train3 = lg3.predict(X_train3)\n",
    "pred_test3 = lg3.predict(X_test3)\n",
    "\n",
    "pred_train3 = np.round(pred_train3)\n",
    "pred_test3 = np.round(pred_test3)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train3) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test3))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train3) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test3))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train3) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test3))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train3) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test3))\n",
    "\n",
    "print(lg3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuarcy increased from .954 to .957\n",
    "* Now let's drop Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = X_train3.drop(['Experience'], axis = 1)\n",
    "X_test4 = X_test3.drop(['Experience'], axis = 1)\n",
    "\n",
    "\n",
    "logit4 = sm.Logit(y_train, X_train4)\n",
    "lg4 = logit4.fit()\n",
    "\n",
    "# Let's check accuracy and recall for this model\n",
    "pred_train4 = lg4.predict(X_train4)\n",
    "pred_test4 = lg4.predict(X_test4)\n",
    "\n",
    "pred_train4 = np.round(pred_train4)\n",
    "pred_test4 = np.round(pred_test4)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train4) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test4))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train4) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test4))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train4) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test4))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train4))\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test4))\n",
    "\n",
    "print(lg4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No change in Accuracy, only the Recall on test data deceased from .67 to .66\n",
    "* Now let's drop Securities_Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train5 = X_train4.drop(['Securities_Account'], axis = 1)\n",
    "X_test5 = X_test4.drop(['Securities_Account'], axis = 1)\n",
    "\n",
    "\n",
    "logit5 = sm.Logit(y_train, X_train5)\n",
    "lg5 = logit5.fit()\n",
    "\n",
    "# Let's check accuracy and precision for this model\n",
    "pred_train5 = lg5.predict(X_train5)\n",
    "pred_test5 = lg5.predict(X_test5)\n",
    "\n",
    "pred_train5 = np.round(pred_train5)\n",
    "pred_test5 = np.round(pred_test5)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train5) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test5))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train5) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test5))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train5) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test5))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train5))\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test5))\n",
    "\n",
    "print(lg5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy and Recall are appoximately same\n",
    "* The difference isn't much, so we can say that lg5 is best model for making inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coefficient of Income, Family, CCAvg, Education,Mortgage and CD_Account are positive, increase in these will lead to increase in chances of taking persoanl loan \n",
    "* Coefficient of Online and CreditCard is negative, increase in these will lead to decrease in chances of taking personal loan\n",
    "* 1 unit change in CCAvg will change the odds of taking a loan by : 15.77%\n",
    "* similarly 1 unit change in Income will change the odds of taking loan by : 5.77%\n",
    "* Family and Education and CD_Account have greater coefficients, so small changes in there value will have bigger change in chances of taking personal loan\n",
    "\n",
    "* Please note that when coefficient is b , than change in odds is (exp(b)-1)*100 %\n",
    "* Probability = odd/(1+odd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It seems like recall score can be impoved further, so let's try to change the model threshold using AUC-ROC Curve\n",
    "* There are no signs of Overfitting\n",
    "* At some place we see that metric is perfoming better on test set, that totally depends on data distribution - if we change the random state then this would change too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that Recall can be improved further, let's try to do that using optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal threshold using AUC-ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal threshold as per AUC-ROC curve\n",
    "# The optimal cut off would be where tpr is high and fpr is low\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, lg5.predict(X_test5))\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction with optimal threshold\n",
    "pred_train_opt = (lg5.predict(X_train5)>optimal_threshold).astype(int)\n",
    "pred_test_opt = (lg5.predict(X_test5)>optimal_threshold).astype(int)\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train_opt) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test_opt))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train_opt) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test_opt))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train_opt) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test_opt))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train_opt))\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AUC-ROC curve to get optimal threshold\n",
    "* Accuracy decreased from .95 to .88\n",
    "* Recall increased from .66 to .91\n",
    "\n",
    "### As we will decrease the threshold value, Precision will go on increasing, but that's not what is needed because that will lead to high marketing cost, we need to choose optimal balance between recall and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us make confusion matrix on train set\n",
    "make_confusion_matrix(y_train,pred_train_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us make confusion matrix on test set\n",
    "make_confusion_matrix(y_test,pred_test_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, lg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lg.predict(X_test))\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Area under the curve is 0.95\n",
    "* Recall is .91 on train and .87 on test that is quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build our model using the DecisionTreeClassifier function. Using default 'gini' criteria to split. Other option include 'entropy'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(criterion = 'gini', random_state=1)\n",
    "dTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = dTree.predict_proba(X_train)\n",
    "pred_train = dTree.predict(X_train)\n",
    "\n",
    "prob_test = dTree.predict_proba(X_test)\n",
    "pred_test = dTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us make confusion matrix on train set\n",
    "make_confusion_matrix(y_train,pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 errors on train data, each sample has been classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us make confusion matrix on test set\n",
    "make_confusion_matrix(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, dTree.predict_proba(X_test)[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, dTree.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(fpr, tpr, label='Decision tree (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overall the output looks good and shows no sign of overfitting in accuracy but if we look at recall, on train set it's 1 while on test it is .89, so we'll use pruning and try to reduce this difference\n",
    "* Area under the curve is also 0.94 that is quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,30))\n",
    "tree.plot_tree(dTree,feature_names=feature_names,filled=True,fontsize=9,node_ids=True,class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print (pd.DataFrame(dTree.feature_importances_, columns = [\"Imp\"], index = X_train.columns).sort_values(by = 'Imp', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dTree.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text report showing the rules of a decision tree -\n",
    "\n",
    "print(tree.export_text(dTree,feature_names=feature_names,show_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Online,CreditCard, Securities_Account, ZIPCode have 0 importance, Education is most important followed by Income and Family size\n",
    "* People with Income less than 116.5 , CCAvg less than 2.95 and Income less than 106.5(1000dollars), have less chances of buying loan\n",
    "* But people having income more than 106.5, Family not of size 4, age less than 28.50 and Experience greater than 3.50 have more chances of taking a loan\n",
    "* People with Income greater than 116.5, did only undergraduation, have family size less than 2 have less chances of buying a loan while People with family size greater than 2, and education level more than undergraduate has more chances of buying a loan\n",
    "     \n",
    "     \n",
    "* So bank should campaign more on people with higher income, More education and larger family sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing over fitting (Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general, the deeper you allow your tree to grow, the more complex your model will become because you will have more splits\n",
    "  and it captures more information about the data and this is one of the root causes of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try Grid search\n",
    "* Hyperparameter tuning is also tricky in the sense that there is no direct way to calculate how a change in then\n",
    "hyperparameter value will reduce the loss of your model, so we usually resort to experimentation. i.e we'll use Gridsearch\n",
    "* Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters. \n",
    "* It is an exhaustive search that is performed on a the specific parameter values of a model.\n",
    "* The parameters of the estimator/model used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "estimator = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_depth': np.arange(6,15), \n",
    "              'min_samples_leaf': [1, 2, 5, 7, 10],\n",
    "              'max_leaf_nodes' : [2, 3, 5, 10],\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(estimator, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "estimator = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = estimator.predict_proba(X_train)\n",
    "pred_train = estimator.predict(X_train)\n",
    "\n",
    "prob_test = estimator.predict_proba(X_test)\n",
    "pred_test = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This doesn't seem to provide good outputs, recall decreased for both train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Complexity Pruning\n",
    "\n",
    "The `DecisionTreeClassifier` provides parameters such as\n",
    "``min_samples_leaf`` and ``max_depth`` to prevent a tree from overfiting. Cost\n",
    "complexity pruning provides another option to control the size of a tree. In\n",
    "`DecisionTreeClassifier`, this pruning technique is parameterized by the\n",
    "cost complexity parameter, ``ccp_alpha``. Greater values of ``ccp_alpha``\n",
    "increase the number of nodes pruned. Here we only show the effect of\n",
    "``ccp_alpha`` on regularizing the trees and how to choose a ``ccp_alpha``\n",
    "based on validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a decision tree using the effective alphas. The last value\n",
    "in ``ccp_alphas`` is the alpha value that prunes the whole tree,\n",
    "leaving the tree, ``clfs[-1]``, with one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the remainder, we remove the last element in\n",
    "``clfs`` and ``ccp_alphas``, because it is the trivial tree with only one\n",
    "node. Here we show that the number of nodes and tree depth decreases as alpha\n",
    "increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1,figsize=(10,7))\n",
    "ax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall vs alpha for training and testing sets\n",
    "----------------------------------------------------\n",
    "When ``ccp_alpha`` is set to zero and keeping the other default parameters\n",
    "of `DecisionTreeClassifier`, the tree overfits, leading to\n",
    "a 100% training Recall and 90% testing Recall. As alpha increases, more\n",
    "of the tree is pruned, thus creating a decision tree that generalizes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_train=[]\n",
    "for clf in clfs:\n",
    "    pred_train3=clf.predict(X_train)\n",
    "    values_train=metrics.recall_score(y_train,pred_train3)\n",
    "    recall_train.append(values_train)\n",
    "    \n",
    "recall_test=[]\n",
    "for clf in clfs:\n",
    "    pred_test3=clf.predict(X_test)\n",
    "    values_test=metrics.recall_score(y_test,pred_test3)\n",
    "    recall_test.append(values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Recall\")\n",
    "ax.set_title(\"Recall vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, recall_train, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, recall_test, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_best_model = np.argmax(recall_test)\n",
    "best_model = clfs[index_best_model]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = best_model.predict_proba(X_train)\n",
    "pred_train = best_model.predict(X_train)\n",
    "\n",
    "prob_test = best_model.predict_proba(X_test)\n",
    "pred_test = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy on train data:',accuracy_score(y_train, pred_train) )\n",
    "print('Accuracy on test data:',accuracy_score(y_test, pred_test))\n",
    "\n",
    "print('Recall on train data:',recall_score(y_train, pred_train) )\n",
    "print('Recall on test data:',recall_score(y_test, pred_test))\n",
    "\n",
    "print('Precision on train data:',precision_score(y_train, pred_train) )\n",
    "print('Precision on test data:',precision_score(y_test, pred_test))\n",
    "\n",
    "print('f1 score on train data:',f1_score(y_train, pred_train) )\n",
    "print('f1 score on test data:',f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Post pruning using ccp alpha seems to have reduced difference between train and test performances but only by reducing model performance on train set, so let's proceed with the basic model we made earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare outputs from Logistic regression and Decision tree\n",
    "* Overall we can see that Decision tree performs better on given dataset\n",
    "* Looking at important variables on the basis of pvalues in Logistic regression and Feature importance in Decision trees\n",
    "    * Income, CCAvg, CD_Account, Family, Education, Mortgage are important in Both\n",
    "    * And looking at their coefficients from logistic Regression shows that increase in these variables leads to increase in chances of buying loan\n",
    "    \n",
    "### Recommendation\n",
    "**Bank should spend more on campaigning for people with income more than 116(thousand dollars), More education(graduate/professional), family size of 3 or more and Mortgage values of greater than 284**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Measures = {'Logistic Regression': [0.95, 0.94, 0.66, 0.59, 0.83, 0.74, 0.73, 0.66],\n",
    "        'LR with opt threshold': [0.88, 0.88, 0.91, 0.87, 0.45, 0.44, 0.60, 0.59],\n",
    "        'Decision Tree': [1, 0.98, 1, 0.89, 1, 0.91, 1, 0.90]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(Measures, columns = ['Logistic Regression','LR with opt threshold', 'Decision Tree'],\n",
    "                  index=['Train_accuracy','Test_accuracy','Train_Recall','Test_Recall','Train_precision','Test_precision','Train_f1_score','Test_f1_score'])\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do misclassification analysis\n",
    "* Is there any certain pattern, followed by samples which are incorrectly classified by our model (dTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = dTree.predict(X) \n",
    "Y1 = Y1.reshape(5000, 1)\n",
    "\n",
    "Y2 = np.subtract(Y ,Y1)\n",
    "\n",
    "# Most of the values in Y2 are 0, only 33 values are either '1' or '-1'\n",
    "# 1 says, Perosn would buy loan but model predicted he won't\n",
    "# -1 says, Perosn won't buy loan but model predicted he would\n",
    "\n",
    "#Let's concatenate this Y2 with X\n",
    "df1 = pd.DataFrame(Y2)\n",
    "df2 = pd.concat([X, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = df2[df2['Personal_Loan'] != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 28 misclassifications and all those are on test data\n",
    "* incorrect_df consists of all misclassified elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since Zipcode was not an important variable in both Logistic Regression and Decision trees. let's drop that - to make \n",
    "# visualization easier\n",
    "\n",
    "incorrect_df = incorrect_df.drop(['ZIPCode_91','ZIPCode_92','ZIPCode_93','ZIPCode_94','ZIPCode_95','ZIPCode_96'], axis = 1)\n",
    "\n",
    "incorrect_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's try to see if there is any specific pattern in these samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at above profile, we see that incorrectly classified people are :\n",
    "* Usually between 28 and 65 age and have experience inbetween 4 to 41 years, with 18 and 20 uniques values\n",
    "* Income varies inbetween 64 to 115(thousand dollars), while usual income varied from 8 to 224(thousand dollars)\n",
    "* Most of the people misclassified have 0 mortgage, no Securities Account and no CD_account, have family size 1 and 2, have profession/Advanced education\n",
    "\n",
    "* On the basis of Business Rule, we derived we were able to see that usually people with income less than 116, less mortgage, family size less than 3 doesn't buy loan - There are special cases always, so some people with less income and smaller family size might also buy loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
